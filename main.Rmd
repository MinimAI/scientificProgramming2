---
title: "Making multivariate statistics reproducible"
output: html_notebook
thanks: "Replication files are available on the author's Github account."
author:
- name: Felix Taschbach
  affiliation: Maastricht University
---
## Load Packages
We begin by installing and loading any required packages. The following code first installs the package pacman, if necessary, and then uses pacman to install, if required, and load the packages needed to run this script.
```{r}
# Clear all variables 
rm(list=ls()) 

# install pacman if necessary
if (!require("pacman")) suppressPackageStartupMessages(install.packages("pacman"))
# install required packages
pacman::p_load("ggplot2", "dplyr","pls","readr","caTools","caret","gplots","car","rcdk","iterators","lattice","latticeExtra")
```
## Importing the data.
To import the data I am first setting the local path to the directory that the data is stored in.
```{r}
DATA.DIR <- "/Users/felix/Google Drive/Uni/Systems Biology/Year 2/Scientific Programming/scientificProgramming2/data"
setwd(DATA.DIR) # set the working directory
```

Afterwards, I import the activity scores. To properly import the activity scores matrix, 2 import function calls are needed: one to import the header and one to import the data.
```{r}
# import the header and the activity scores
headers <- read.csv('aid624202.csv', header=FALSE, nrows=1, as.is=TRUE, row=1)
data.raw <- read.csv('aid624202.csv',skip=6,header=FALSE,row=1)
colnames(data.raw) <- headers                                       # change the names of the data to the correct ones
data.raw <- data.raw[,c("PUBCHEM_SID","PUBCHEM_ACTIVITY_SCORE")]     # select SID and the activity score from the data
colnames(data.raw) <- c("SID","Score")                               # change column names
```

## Data cleaning
Columns that contain missing values and columns that are nearly constant are dropped from the dataframe.
```{r}
# Delete columns with missing values
descs <- data[, !apply(data, 2, function(x) any(is.na(x)) )]

# Delete columns with near zero variance using nearZeroVar from the caret package
badCols <- nearZeroVar(descs)
descs <- descs[, -badCols]

# further filter out columns with low correlation
r2 <- which(cor(descs[1:(length(descs)-1)])^2 > .29, arr.ind=TRUE)
r2 <- r2[ r2[,1] > r2[,2] , ]
d <- descs[, -unique(r2[,2])]
```
## Normalizing the data 
Then the data is normalised to stabilise its variance. The data transformation makes the data more normal distribution-like and improves the validity of measures of association such as the Pearson correlation between variables and for other data stabilization procedures.
```{r}
# use preProcess from the caret package to normalize the filtered data
data <-predict(preProcess(d[,1:dim(d)[2]],method = "BoxCox"),d[,2:dim(d)[2]])
```
## Subset the data
The data is subset into a testset/ trainset with a 20% / 80% split.
```{r}
# subset the data into train and test sets
ind<-sample(2,nrow(data),replace=TRUE,prob=c(0.8,0.2))
trainset_x<-data[ind==1,1:dim(data)[2]]
train_y<-trainset_x$activity
testset_x<-data[ind==2,1:dim(data)[2]]
test_y<- testset_x$activity
```